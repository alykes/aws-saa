## Section 9 - RDS, Aurora and Elasticache

### Relational Database Service (RDS)  
- RDS stands for Relational Database Service  
- It's a managed DB Service for DBs that use SQL as a Query Language  
- It allows you to create databases in the cloud that are managed by AWS  
  - Postgres  
  - MySQL  
  - MariaDB  
  - Oracle  
  - Microsoft SQL Server  
  - IBM DB2  
  - Aurora (AWS Proprietary database)  

### Advantages of using RDS over deploying a DB on an EC2 instance  
- RDS is a managed service:  
  - Automated provisioning  
  - continuous backups and the ability to restore to a point in time (PTR)  
  - monitoring of the database resources  
  - read replicas for improved read performance  
  - multi AZ setup for DR  
  - maintenance window for upgrades  
  - scaling capability (either vertical or horizontal)  
  - storage backed by EBS (gp2, gp3, io1, io2 or magnetic)  
- `EXAM TIP`: **You cannot SSH into an RDS instance**  

### RDS Storage Auto Scaling  
- helps increase storage on your RDS DB instance dynamically  
- when RDS detects that it is running out of DB space, it scales automatically  
- avoid manually scaling your database scaling  
- you need to set a `Maximum storage threshold` (maximum limit for DB storage)  
- Automatically modify storage if:  
  - free storage is < 10% of allocated storage  
  - low-storage lasts for at least 5 minutes  
  - 6 hours have passed since the last modification  
- Useful for applications with `unpredictable workloads`  
- Supports all RDS database engines  

### RDS Read Replicas vs Multi AZ  
- You can have up to `15` read replicas  
- They can be placed within an AZ, Cross AZ or Cross Region  
- Replication is `asynchronous`, therefore reads are **everntually** consistent  
- replicas can be promoted to their own DB  
- Applications must update the connection string to leverage read replicas  

### RDS Read Replicas - Use Cases  
- You have a production DB with a normal load  
- You require a reporting application to run some analytics  
- A read replica is a good use case here to run the new workload  
- Leaving the production database unaffected  
- Read replicas are used for `SELECT` statements not `INSERT`, `UPDATE` or `DELETE`  

### RDS Read Replicas - Network Cost  
- In AWS there's a network cost associated when data goes from one AZ to another AZ (there are exceptions for some services)  
- `EXAM TIP`: **For Read Replicas within the same region, you DO NOT PAY this fee**  

### RDS Multi AZ - Disaster Recovery  
- The replication is `synchronous`  
- There is **one DNS name**; which facilitates automatic failover to the standby  
- Increases Availability  
- Good failover strategy in case of the loss of:  
  - An AZ  
  - An instance  
  - Storage  
- No manual intervention in apps, that is, you don't need to amend connection strings  
- **Not used for scaling!**
- `EXAM TIP`: **Read Replicas can be set up as Multi AZ for a DR scenario**  

### RDS - From Single AZ to Multi AZ  
`EXAM TIP - Common scenario`
- Zero downtime operation - You don't need to stop the DB  
- Just click on **modify** and configure **Multi-AZ** it in there  
- The following will happen:  
  - A snapshot is taken  
  - A new DB is restored from the snapshot into a new AZ  
  - Synchronisation is established between the two databases  
  - The main DB will not be stopped!

### RDS Custom  
- `EXAM TIP`: Two databases that allow RDS Custom are: 
  - Oracle   
  - Microsoft SQL Server Database  
  - `RDS`: Automates setup, operation and scaling of databases in AWS  
  - `Custom`: access to the underlying database and OS so that you can:  
    - configure settings  
    - install patches  
    - enable native features  
    - access the underlying EC2 instance using **SSH** or **SSM Session Manager**  
- `De-activate Automation Mode` allows you to perform customisations  
  - Best practise is to take a snapshot first  
- `RDS vs RDS Custom`  
  - `RDS`: entire database and the OS is managed by AWS  
  - `RDS Custom`: full admin access to the uderlying OS and database  

### Aurora  
- Aurora is proprietary technology from AWS (not open source)  
- Postgres and MySQL are both supported as Aurora DBs  
- Aurora is **AWS cloud optimised** and claims to have:  
  - `5x` performance improvement over MySQL on RDS  
  - `3x` performance improvement over Postgres on RDS  
- Storage automatically grows in increments of 10GB, up to 128TB  
- Aurora can have up to 15 read replicas and the replication process is faster than MySQL (less than 10ms replica lag)  
- Failover in Aurora is instantaneous. It is HA native  
- Aurora costs about 20% more than RDS - but boasts more efficiency  

### Aurora - High Availability and Read Scaling  
- `6 copies` of your data across `3 AZs`:  
  - `4 copies` out of 6 needed for `writes`   
  - `3 copies` out of 6 needed for `reads`  
  - self-healing with peer-to-peer replication  
  - storage is striped across 100s of volumes  
- One Aurora instance takes writes (master)  
- Automated failover for master in less than 30 seconds  
- Master plus up to 15 Aurora Read Replicas serve reads  
- Support for Cross Region Replication  

### Aurora DB Cluster  
- There is one master that does all the writing to the storage  
  - The master has a `writer endpoint` that always points to the master, and this is where clients write to  
- There are a bunch of read replicas, up to a max of 15.
  - They can be set up for auto-scaling 
    - based on two metrics:  
      - average CPU  
      - average connections 
  - They read from storage    
  - The read-replica cluster has a `reader endpoint` that allows clients read from storage  
  - The reader-endpoint load balances the read requests coming in from clients  
  - `EXAM TIP`: **The Load Balancing happens at the connection level, not the statement level!**  

### Aurora Features  
- Automatic fail-over  
- Backup and recovery  
- Isolation and security  
- Industry compliance  
- Push button scaling  
- Automated patching with zero down-time  
- Advanced monitoring  
- Routine maintenance  
- `Backtrack`: restore data to any point in time without using backups

### Aurora - Advanced Concepts  
- `Read Replica Auto Scaling` happens when your auto-scaling policy is created and metric condition (CPU or connection) is met for horizontal scaling to take place  
  - The reader endpoint must now accomodate the new read replicas in the cluster and we have the `Endpoint Extended` to include them  
- `Custom Endpoints`  
  - say you have a mismatch of instance types for the read replicas, some are `.xlarge` and some are `.large`  
  - you can define a subset of the aurora instances as `custom endpoints`  
  - an example would be to set up two custom endpoints, one for the `.xlarge` instances and another for the `.large` instances  
  - Use Case: To run analytical queries on specific replicas that have larger CPU and RAM, allowing faster response times  
- `Aurora Serverless`  
  - Automated database instantiation and auto-scaling based on actual usage  
  - Good option for infrequent, intermittent or unpredictable workloads  
  - No capacity planning is required  
  - You pay per second and can be more cost-effective  
  - **Traffic Flow**: A client talks to a `Proxy Fleet` that is managed by Aurora
- `Global Aurora`  
  - `Aurora Cross Region Read Replicas`  
    - useful for disaster recovery  
    - simple to put in place  
  - `Aurora Global Database (Recommended)`  
    - 1 primary region (read/write)  
    - up to 5 secondary (read-only) ragions, replication lag is < 1 second  
    - Up to 16 Read Replicas per secondary region  
    - helps for decreasing latency  
    - promoting another region (for disaster recovery) has an RTO of < 1 minute  
    - `EXAM TIP`: **Typical corss-region replication takes less than 1 second**  
- `Aurora Machine Learning`  
  - Enables you to add ML-based predictions to your applications via SQL  
  - simple, optimised and secure integration between Aurora and AWS ML services  
  - Supported Services:  
    - Amazon SageMaker (use with any ML model)  
    - Amazon Comprehend (for sentiment analysis)  
  - You don't need to have ML experience  
  - Use Cases: **fraud detection, ad targeting, sentiment analysis, product recommendations**  

### RDS and Aurora - Backup and Monitoring  
- `Backups`  
  - `Automated Backups`  
    - Daily full backup of the DB (during a specified backup window)  
    - transaction logs are backed up by RDS every 5 minutes  
    - ability to restore to any point in time (from oldest backup; from 5 minutes ago)  
    - 1 to 35 day retention of backups, you can set to 0 to disable automated backups  
  - `Manual DB Snapshots`  
    - Manually triggered by the user  
    - retention of backup for as long as required  
  - `EXAM TIP`: **in a stopped RDS database you will still pay for storage. If you plan on stopping it for a long time, you should snapshot (cheaper) and restore instead.**   
- `Aurora Backups`  
  - `Automated Backups`  
    - 1 to 35 days of retention; backups can't be disabled  
    - point in time recovery can be performed in this timeframe  
  - `Manual DB Snapshots`  
    - Manually triggered by the user  
    - retention of backup for as long as required  
- `RDS & Aurora Restore Options`  
  - `EXAM TIP`: **Restoring an RDS/Aurora backup or snapshot creates a new database**  
  - `Restoring MySQL RDS database from S3`  
    - create a backup of your on-prem DB  
    - store it on Amazon S3  
    - restore the backup file onto a new RDS instance running MySQL  
  - `Restoring MySQL Aurora Cluster from S3`  
    - Create a backup of your on-prem DB using `Percona XtraBackup`  
    - store the backup file on Amazon S3  
    - restore the backup file onto a new Aurora cluster running MySQL  
- `Aurora Database Cloning`  
  - Creates a new Aurora DB Cluster from an existing one  
  - faster than a snapshot & restore  
  - uses `copy-on-write` protocol  
    - initially the new DB cluster uses the same data volume as the original DB cluster (fast and efficient as no copying is needed)  
    - when updates are made to the new DB cluster data, then additional storage is allocated and the data is copied to be seperated  
  - very fast and cost-effect  
  - `EXAM TIP`: **useful to create a "staging" database from a "production" database without impacting the production DB**  

### RDS Security  
- `Encryption At-Rest`  
  - data is encrypted on the storage volume  
  - database master & replicas encryption using AWS KMS - must be defined at launch time  
  - if the master is not encrypted, the read replicas cannot be encrypted  
  - to encrypt and un-encrypted database, select a DB snapshot and restore it as `encrypted`  
- `Encryption In-Transit` aka `In-Flight`  
  - TLS ready by default, use the AWS TLS root certificates client-side  
- `IAM Authentication`  
  - Use **IAM roles** to connect to the database (instead of the traditional username/password)  
- `Security Groups`  
  - Control network access to your RDS / Aurora DB  
- `No SSH available` except on RDS custom  
- `EXAM TIP`: **Audit logs can be enabled and sent to cloudwatch logs for longer retention**  

### Amazon RDS Proxy   
- Fully managed database proxy for RDS  
- allows apps to pool and share DB connections established with the database  
- `EXAM TIP`: **improving the database efficiency by reducing the stress on database resources (CPU/RAM) and minimises open connections (and timeouts)  
- Serverless, autoscaling, highly available (multi-AZ)  
- `EXAM TIP`: **Reduced RDS and Aurora failover time by up to 66%**  
- supports RDS (MySQL, Postgres, MariaDB, MS SQL Server) and Aurora (MySQL, Postgres)  
- No code changes are required for most apps
- `EXAM TIP`: **Enforce IAM Authentication for DB, and securely store credentials in AWS Secrets Manager**  
- `EXAM TIP`: **RDS Proxy is never publicly accessible (MUST be accessed from a VPC)**  
- lambda functions benefit from an RDS Proxy as they can potentially make thousands of connections in a short amount of time!  

### Elasticache  
- ElastiCache is used to instantiate a **Redis** or **memcached** database 
- Caches are `in-memory` with `high performance` and `low latency`  
- Helps reduce the load from the database for read intensive workloads  
- Helps make your application stateless  
- AWS takes care of OS, patching, maintenance, optimisation, configuration, monitoring, failover, backups etc  
- Fully managed service  
- `EXAM TIP`: **Using Elasticache requires heavy application code changes**   

### Elasticache Solution Architecture - DB Cache  
- Applications query Elasticache, if the data is not available in the cahce, the data is retreived from the RDS instance and stored in Elasticache  
- Helps relieve the load on the RDS instance  
- Cahce must have an invalidation strategy to make sure only the most current data is used  

### Elasticache Solution Architecture - User Session Store  
- User logs into any of the applications  
- The application writes the session data into Elasticache  
- The user hits another instance of the application  
- The instance retrieves the cached session data from the cache and therefore verifies that the user is already logged in  

### Elasticache - Redis vs Memcached  
- `Redis`  
  - Multi AZ with auto-failover  
  - read replicas to scale reads and have High Availability  
  - data durability using AOF persistence  
  - Backup and restore features  
  - `EXAM TIP` : **Supports Sets and Sorted Sets**  
- `Memcached`  
  - Multi-node for partitioning of data (sharding)  
  - No High Availability (no replication)  
  - Non persistent cache  
  - No backup and restore  
  - Multi-threaded architecture  

### Elasticache for Solution Architecture Exam  
- Elasticache supports **IAM Authentication for Redis only**  
- IAM policies on Elasticache are only used for AWS API-level security  
- `Redis AUTH`  
  - you can set a password/token when you create a redis cluster  
  - this is an extra level of security for your cache (on top of secuerity groups)  
  - supports SSL in flight encryption  
- `memcached`  
  - `EXAM TIP`: **supports SASL-based authentication (advanced topic)**   

### Patterns for Elasticache  
- `Lazy Loading`  
  - all the read data is cached, data can become stale in cache  
- `Write Through`  
  - adds or updates data in the cache when written to a DB (there is no stale data)  
- `Session Store`  
  - stored temporary session data in a cache using TTL features  

### Elasticache - Redi Use Case  
- `EXAM TIP - SCENARIO` 
- Gaming Leaderboards are computationally complex  
- `Redis sorted sets` guarantee both uniqueness and element ordering  
- each time a new element is added, it's ranked in real time and then added in the correct order  

### List of standard ports to become familiar with 
- `Important ports`:
- FTP: 21
- SSH: 22
- SFTP: 22 (same as SSH)
- HTTP: 80
- HTTPS: 443

`RDS Databases ports`:
- PostgreSQL: 5432
- MySQL: 3306
- Oracle RDS: 1521
- MSSQL Server: 1433
- MariaDB: 3306 (same as MySQL)
- Aurora: 5432 (if PostgreSQL compatible) or 3306 (if MySQL compatible)

### Quiz Results  
- Attempt 1: 22/25 (88%)  

